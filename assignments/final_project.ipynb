{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba86554b-6de7-4146-9a3a-4b16446c865c",
   "metadata": {},
   "source": [
    "# Intermediate Project Notes: Link Predictions\n",
    "> Yixuan Liu, 2024/10/16\n",
    "> \n",
    "> Prelim contents for final project"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b7078ce5-bce0-45e7-a040-3afa051b9aeb",
   "metadata": {},
   "source": [
    "## 1. Introduction of link prediction\n",
    "### Basic idea\n",
    "\n",
    "- Goal: given a graph $G(V,E)$ predict future/missing links between nodes\n",
    "- General approach: The prediction process often involves calculating a **similarity score** between two nodes, where a higher score indicates a higher likelihood of a future or missing link. The similarity can be based on network topology, node attributes, or learned node embeddings.\n",
    "- Applications: friendship connections, recommender systems, drug discovery, PPI, etc\n",
    "\n",
    "<img src=\"https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41598-019-57304-y/MediaObjects/41598_2019_57304_Fig1_HTML.png?as=webp\" alt=\"Graph Illustration\" width=\"600\"/>\n",
    "\n",
    "\n",
    "### Measuring performance\n",
    "- Accuracy, Precision, Recall, and F1-Score\n",
    "- AUC-ROC, AUC-PR\n",
    "- MRR (mean reciprocal rank), Hit Rate: Focus on ranking performance, useful for algorithms that produce a ranked list of link predictions.\n",
    "    - MRR: how high the true positive links are ranked compared to the false positives. It is often used in algorithms that output a ranked list of link predictions. $Q$ is the set of all queries (node pairs). And $rank_i$ the position of the first relevant link for the $i-th$ query.\n",
    "      $$\\operatorname{MRR}=\\frac{1}{|Q|} \\sum_{i=1}^{|Q|} \\frac{1}{\\operatorname{rank}_i}$$\n",
    "- Kendall’s Tau, MAP (Mean Average Precision): Evaluate the quality of rankings generated by the algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38af6fb0-72f3-42d6-af7e-3053a30c3b55",
   "metadata": {},
   "source": [
    "***\n",
    "## 2. Topological predictors\n",
    "Simple functions of the observed network topology. Mixure/stacking of these predictors could be found in [Gasemian et al,2020](https://www.pnas.org/doi/10.1073/pnas.1914950117). (or also look the review paper to see there is more)\n",
    "\n",
    "### Global predictors\n",
    "Quantify various network-level statistics and are inherited by each pair of nodes i,j that is a candidate missing link. Their primary utility is to provide global context to other predictors under supervised learning.\n",
    "#### Example: # nodes, # edges, average degree, variance of the degree distribution, network diameter\n",
    "\n",
    "### Pairwise predictors\n",
    "These predictors are functions of the joint topological properties of the pair of nodes i, j being considered.\n",
    "\n",
    "#### Example 1: Common Neighbours\n",
    "The number of common neighbors between node *i* and node *j*.\n",
    "\n",
    "$$CN(i, j) = | \\Gamma(i) \\cap \\Gamma(j) |$$\n",
    "\n",
    "Where:\n",
    "- $\\Gamma(i), \\Gamma(j)$ is the set of neighbours of node *i*, noe *j*\n",
    "\n",
    "#### Example 2: Jaccard Index\n",
    "The Jaccard index measures the similarity between two sets by comparing the size of their intersection and union.\n",
    "\n",
    "$$\n",
    "J(i, j) = \\frac{| \\Gamma(i) \\cap \\Gamma(j) |}{| \\Gamma(i) \\cup \\Gamma(j) |}\n",
    "$$\n",
    "\n",
    "#### Example 3: Adamic-Adar Index\n",
    "The Adamic-Adar index assigns higher importance to less-connected neighbours.\n",
    "\n",
    "$$AA(i, j) = \\sum_{k \\in \\Gamma(i) \\cap \\Gamma(j)} \\frac{1}{\\log |\\Gamma(k)|}$$\n",
    "\n",
    "Where:\n",
    "- *k* is a common neighbour of nodes *i* and *j*\n",
    "- $\\Gamma(k)$ is the degree (number of neighbours) of node *k*\n",
    "\n",
    "### Node based predictors\n",
    "These predictors are functions of the independent topological properties of the individual nodes $i$ and $j$, and thus produce a **pair of predictor values**. the particular function that converts the pair of node-based predictors into a score is learned within the supervised framework (e.g. Euclidean distance, cosine similarity).\n",
    "#### Examples: degree, local clustering coeffcient, eigenvector centrality, PageRank, Katz centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc24476c-193c-4885-8b20-50d21c9706b7",
   "metadata": {},
   "source": [
    "***\n",
    "## 3. Model-based predictors\n",
    "\n",
    "### likelihood predictors\n",
    "- Maximizing likelihood to the parametric model $\\operatorname{Pr}(i \\rightarrow j \\mid \\theta)$ by decomposing the network under a probabilistic generative model of network structure.\n",
    "#### Example: Stochastic block model ([Newman and Reinert, 2016](https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.117.078301))\n",
    "\n",
    "### optimization predictors\n",
    "- Score each pair $i, j$ according to whether adding them would increase a corresponding (non-probabilistic) objective function, like in the Map Equation or the modularity function.\n",
    "#### Example: Modularity, Girvan-Newman ([Newman and Girvan, 2004](https://journals.aps.org/pre/abstract/10.1103/PhysRevE.69.026113))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b91a61e-9355-4974-b6b0-f1ab646ffb36",
   "metadata": {},
   "source": [
    "*** \n",
    "## 4. Embedding-based approaches\n",
    "Find the closest node pairs based on proximity in the embedded space. (Let's not go too deep, could use some Python packages like **stellargraph** but it would be better with **PyTorch** environment)\n",
    "### Random walk-based\n",
    "Idea: nodes frequently appearing together in random walks should have similar embedding. Treating walks as sequences of nodes.\n",
    "$$\\max _{\\mathbf{Z}} \\sum_{(u, v) \\in E} \\log \\sigma\\left(\\mathbf{Z}_u^{\\top} \\mathbf{Z}_v\\right)+\\sum_{\\left(u^{\\prime}, v^{\\prime}\\right) \\notin E} \\log \\left(1-\\sigma\\left(\\mathbf{Z}_{u^{\\prime}}^{\\top} \\mathbf{Z}_{v^{\\prime}}\\right)\\right)$$\n",
    "#### Example: DeepWalk ([Perrozi et al., 2014](https://dl.acm.org/doi/10.1145/2623330.2623732)), node2vec ([Grover and Jeskovec, 2016](https://dl.acm.org/doi/10.1145/2939672.2939754))\n",
    "\n",
    "### Graph Neural Networks (GNNs)\n",
    "Idea: node aggregates feature information from its neighbors, passes it through a neural network, and updates its representation.\n",
    "$$\\mathcal{L}=\\sum_{(u, v) \\in E} \\operatorname{Loss}(1, s(u, v))+\\sum_{\\left(u^{\\prime}, v^{\\prime}\\right) \\notin E} \\operatorname{Loss}\\left(0, s\\left(u^{\\prime}, v^{\\prime}\\right)\\right)$$\n",
    "#### Example: GAT ([Velicˇkovic ́ et al., 2018](https://arxiv.org/pdf/1710.10903)), GCN ([Kipf et al, 2016](https://arxiv.org/abs/1609.02907)), GraphSAGE ([Hamilton et al, 2017](https://arxiv.org/abs/1706.02216))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee08806-a5ba-48ec-8135-2c24eea454e8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 5. Case study: \n",
    "- Some baseline datasets, but some more decided by node features, some more about network topology: CORA, or [OGB](https://ogb.stanford.edu/docs/leader_linkprop/#ogbl-ddi) ?. Compare several methods and their performance.\n",
    "- Data set might be: drug-drug interaction, collboration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9959cdf-8b6a-47cb-ac32-a869c836343e",
   "metadata": {},
   "source": [
    "## 6. Discussions:\n",
    "\n",
    "### Homophily vs. Heterophily (bipartite networks, Laszlo lovac, similarity complementary implementation)\n",
    "\n",
    "- Homophily suggests that similar nodes are more likely to connect, whereas heterophily implies connections between dissimilar nodes.\n",
    "- Homophily-based methods (like common neighbors or Jaccard) work well for networks where similar nodes are connected, but they struggle in heterophilic networks.\n",
    "- For networks formed through heterophily (e.g., connections between dissimilar or complementary nodes), we might need different predictors or additional features (such as node attributes) to account for these dissimilarities.\n",
    "Different Node and Edge Features:\n",
    "\n",
    "### Node and link features\n",
    "- Many link prediction methods primarily use topology for prediction, but in real-world scenarios, we also have node features (e.g., user interests in social networks) and edge features (e.g., interaction strength, type of connection).\n",
    "- Model-based approaches or embedding techniques that can incorporate both node features and edge features (e.g., GraphSAGE, GCN) are needed to capture these richer relationships.\n",
    "\n",
    "### Homogeneous and heterogeneous graph\n",
    "- In heterogeneous graphs, different types of nodes and edges exist (e.g., user-product networks, author-paper-venue networks).\n",
    "- Standard link prediction algorithms may not perform well in such settings as they assume homogeneous networks (i.e., all nodes and edges are of the same type).\n",
    "- More advanced methods like heterogeneous graph neural networks (HGNNs) are required to handle the complexity of these diverse relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c8f4ad-ae47-4ea7-810d-8d96192bd002",
   "metadata": {},
   "source": [
    "## Comments from @Brennan and @Alyssa\n",
    "- Objective functions, then look at it, why it is better\n",
    "- Why would we have more methods of GNN? Which does it suit\n",
    "- Karate club example: delete some edges\n",
    "- Bipartite networks, Laszlo lovac, similarity complementary implementation\n",
    "- Gasemian et al,2020. (or also look the review paper to see there is more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c1bf03-9cfe-4b18-b67d-16b8993e29b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
